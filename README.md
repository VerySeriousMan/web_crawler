# 爬虫系统（selenium与requests框架）

**`web_crawler`** 是一个基于Python selenium与requests框架构建的专业网络爬虫系统，专注于高效、稳定地抓取互联网上公开并合法的图片和视频资源。项目采用模块化设计，支持多种主流网站的图片和视频爬取，并具备良好的扩展性。

> 📌 当前版本：`v1.1` ｜ 🆕 [查看更新日志 »](#更新日志)

---

## 技术架构

- 反爬策略：
    - 动态代理IP管理
    - 随机User-Agent中间件
    - 随机请求频率控制
    - 完整的请求头部构建
    - 完整的请求参数构建
    - 请求伪装机制
- 模块化爬虫代码，可配置化设计：
    - 可灵活调整各项爬虫参数
    - 模块化爬虫设计，便于扩展新站点支持
- 高效自动化错误处理：
    - 异常处理机制
    - 错误重试机制
- 配置`start_crawler.py`，一键式项目启动：
    - 保存地址
    - 爬取关键词
    - 爬取数量
    - 爬取网站
    - 高效扩展配件：
        - 高并发代理测试
        - 指定浏览器启动与配置
- 完整配套日志与数据管理
    - 日志管理
    - 下载数据管理
    - 历史记录管理
    - 爬取数量管理

---

## 支持网站
### web_crawler（selenium与requests框架）
| 网站名称      | 图片爬虫 | 视频爬虫 |
|-----------|------|------|
| 淘宝        | -    | ✓    |
| 京东        | -    | ✓    |
| Amazon    | -    | ✓    |
| 哔哩哔哩      | -    | ✓    |
| 抖音        | -    | ✓    |
| 小红书       | ✓    | ✓    |
| 百度贴吧      | ✓    | -    |
| YouTube   | -    | ✓    |
| petfinder | ✓    | -    |

###### web_spiders（scrapy框架）
| 网站名称      | 图片爬虫 | 视频爬虫 |
|-----------|------|------|
| 百度图片      | ✓    | -    |
| Bing图片    | ✓    | -    |
| 360图片     | ✓    | -    |
| 搜狗图片      | ✓    | -    |

---

## 项目结构
```
web_crawler/
├── .gitignore
├── CHANGELOG.md
├── README.md
├── config.py  # 存储配置参数、路径地址与数据导入、更新、保存配置相关代码
├── history/  # 历史信息存储路径，用于查重
├── logger.py  # 日志模块
├── plugins/  # 启动器扩展功能模块
│   ├── __init__.py
│   ├── open_chrome.py  # 打开指定配置的浏览器
│   └── proxy_test.py  # 代理测试
├── settings/
│   ├── basic_setting.toml  # 基础爬虫配置参数
│   ├── chrome_setting.toml  # 浏览器配置
│   ├── cookies/  # 各登录cookies存储
│   │   ├── load_cookies.toml
│   │   └── www.bilibili.com.txt
│   └── lake/
│       ├── proxies.txt  # 代理池
│       └── user_agents.txt  # 备用UA池
├── spiders/  # 各网页爬虫代码
│   ├── __init__.py
│   ├── amazon.py
│   ├── baidutieba.py
│   ├── bilibili.py
│   ├── douyin.py
│   ├── jd.py
│   ├── pet_finder.py
│   ├── taobao.py
│   ├── xhs.py
│   └── youtube.py
├── start_crawler.py  # 爬虫系统启动代码
└── utils/  # 通用工具代码
    ├── __init__.py
    ├── generic_utils.py
    └── log_utils.py  # log记录函数
```
---

## 更新日志

### V1.1

### 2025-06-20

### ✨ 新增功能

1. **新增`start_crawler` 启动器**  
新增一键式爬虫启动脚本 `start_crawler.py` 实现一键式项目启动，可以快速高效的启动所需的爬虫项目
  - ① 集成化配置管理（通过 `config` 模块）：
    - 保存地址
    - 爬取关键词
    - 爬取类型
    - 其他的各参数配置
  - ② 高效的启动扩展配件（`plugins` 模块）：
    - 高并发代理测试
    - 指定浏览器启动与配置
  - ③ 爬虫项目一键配置：
    - 一键启动指定一个或多个网站爬虫
    - 集成化配置爬取参数：
        - 爬取数量
        - 使用浏览器与浏览器参数配置
        - 爬取进度，是否使用已有数据
        - 是否手动登录

2. **新增全系统日志管理**  
配置 `logger` 模块实现统一的日志记录系统
  - ① 覆盖所有爬虫模块与函数的操作记录
    - 标准化日志格式（时间戳、模块名、日志级别、消息）
    - 爬虫全流程日志记录
    - 支持关键操作审计（如浏览器启动、代理测试、爬虫执行）
    - 错误异常自动捕获并记录
    - 日志自动命名与保存
  - ② 配置 `log_utils.py` 实现高效的启动与结束记录
    - 爬取信息记录（网站、爬取类型、保存地址等配置信息）
    - 历史数据统计与记录
    - 本次爬取数据统计与记录
    - 个性化运行统计信息（本次爬虫总耗时时间等）

### ⚙️ 功能优化

1. **项目结构重构**  
  - ① 重构目录结构
    - `history` 文件夹：新增idx保存文件，并规范化url保存文件
    - 各爬虫代码归于 `spiders` 文件夹，并配置 `__init_.py` ,定义包的公共接口 
    - 新增与拆分工具类函数归于 `utils` 文件夹，并配置 `__init_.py` ,定义包的公共接口 
    - 新增 `plugins` 文件夹，保存启动器扩展配件，并配置 `__init_.py` ,定义包的公共接口 
    - 配置相关文件与文件夹
  - ② 重构爬虫结构
    - 配置 `run()` 函数，作为统一启动接口
    - 配置统一的历史数据、全局参数导入与初始化模块，配置数据自动保存导出模块
    - 增加日志模块，配置各日志信息：
        - 历史数据导入自动记录
        - 各运行日志分级记录
        - 异常数据捕获与记录
        - 结束运行数据自动统计
  - ③ 重构配置结构，提取各信息配置相关内容，将各配置参数、数据导入、更新、导出统一管理
    - 新增 `cookies` 保存各登录cookie
    - 新增 `basic_setting.toml` 保存基础爬虫参数配置
    - 新增 `chrome_setting.toml` 保存浏览器配置参数
    - 移动 `lake` 路径实现统一记录
    - 优化配置 `config.py` 模块：
        - 保存各地址路径、参数配置与默认参数设置
        - 新增索引获取与更新函数，url初始化函数，历史记录地址获取函数等配置功能 

2. **优化README**
  - ① 增加技术架构、项目结构，优化项目介绍
  - ② 新增CHANGELOG，优化更新日志

### 📜 完整更新日志

 **点此查看所有历史版本和详细改动说明：**  
🔗[查看完整更新日志 »](CHANGELOG.md)

---
## ⚠️ 使用须知（Usage Notice）

本项目由 **VerySeriousMan** 开发，基于 **CC BY-NC 4.0 License** 开源，**仅供学习与非商业用途使用**。

使用本项目代码时，你必须遵守以下条件：

- 严禁将本项目用于任何商业用途（包括但不限于：收费产品、商业服务、企业平台等）。
- 严禁用于违反相关法律法规或第三方网站服务协议的行为，例如：
  - 未经授权的数据抓取（尤其是涉及敏感信息、隐私数据）
  - 网络攻击、绕过身份验证、爬取受保护内容等行为
  - 利用本代码从事黑灰产、数据贩卖、侵犯隐私等非法活动

开发者已在 LICENSE 中明确免责：**因使用本项目所引起的一切法律风险、数据后果、第三方责任，由使用者自行承担**。

如需商业授权或合作，请联系作者获得书面许可。

## 贡献

欢迎贡献代码！

## 作者

- **ZhangYuetao** - 项目开发者
- 邮箱: zhang894171707@gmail.com